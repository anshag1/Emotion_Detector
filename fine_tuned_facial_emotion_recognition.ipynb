{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine-Tuned Facial Emotion Recognition with Transfer Learning (VGG16)\n","Uses transfer learning, advanced augmentation, and best practices for improved FER2013 accuracy.\n","\n","**Steps:** Install packages, upscale images to 224x224 and convert grayscale to RGB, use VGG16, train with callbacks, save best model, and test in real time."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1. Install required libraries\n","!pip install tensorflow keras opencv-python numpy matplotlib pandas scikit-learn --quiet\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n","TensorFlow version: 2.15.0\n"]}],"source":["# 2. Imports\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","import numpy as np, cv2, os, matplotlib.pyplot as plt, datetime\n","print('TensorFlow version:', tf.__version__)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 22968 images belonging to 7 classes.\n","Found 5741 images belonging to 7 classes.\n"]}],"source":["batch_size = 64\n","def gray2rgb_resize(img):\n","    import cv2\n","    # img is 2D (h, w, 1)\n","    if img.shape[-1] == 1:\n","        img = img.squeeze(-1)\n","        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","    img = cv2.resize(img, (224, 224))\n","    return img\n","\n","train_aug = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n","    zoom_range=0.2, shear_range=0.2, horizontal_flip=True, validation_split=0.2,\n","    preprocessing_function=gray2rgb_resize\n",")\n","\n","train_gen = train_aug.flow_from_directory(\n","    'data/train',\n","    target_size=(224, 224),   # Change from (48,48) to (224,224)\n","    color_mode='rgb',         # Change from 'grayscale' to 'rgb'\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='training'\n",")\n","\n","val_gen = train_aug.flow_from_directory(\n","    'data/train',\n","    target_size=(224, 224),   # Change here as well\n","    color_mode='rgb',         # Change here as well\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=True,\n","    subset='validation'\n",")\n","\n","steps_train = train_gen.samples // batch_size\n","steps_val = val_gen.samples // batch_size\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," global_average_pooling2d_1  (None, 512)               0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 512)               2048      \n"," chNormalization)                                                \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 14982983 (57.16 MB)\n","Trainable params: 7346695 (28.03 MB)\n","Non-trainable params: 7636288 (29.13 MB)\n","_________________________________________________________________\n"]}],"source":["# 4. Load pre-trained VGG16 for transfer learning\n","vgg = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n","for layer in vgg.layers[:-4]: layer.trainable = False  # fine-tune only last 4 conv layers\n","x = vgg.output\n","x = GlobalAveragePooling2D()(x)\n","x = BatchNormalization()(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","preds = Dense(train_gen.num_classes, activation='softmax')(x)\n","model = Model(inputs=vgg.input, outputs=preds)\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","WARNING:tensorflow:From c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n","\n","WARNING:tensorflow:From c:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n","\n","310/358 [========================>.....] - ETA: 3:10 - loss: 1.6363 - accuracy: 0.3627"]}],"source":["# 5. Training callbacks\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1),\n","    ModelCheckpoint('best_emotion_vgg16.h5', save_best_only=True, monitor='val_loss', verbose=1)\n","]\n","epochs = 30\n","history = model.fit(\n","    train_gen,\n","    steps_per_epoch=steps_train,\n","    validation_data=val_gen,\n","    validation_steps=steps_val,\n","    epochs=epochs,\n","    callbacks=callbacks\n",")\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Press 'q' to quit.\n"]}],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Notes\n","- Training may take significant GPU time.\n","- Will likely increase validation accuracy substantially over base CNN.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":5}
